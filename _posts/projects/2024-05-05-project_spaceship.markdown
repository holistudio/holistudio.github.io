---
layout: post
title:  "Project Spaceship"
date:   2023-06-14 18:47:00
preview: /assets/img/preview_spaceship.png
---

![SPACESHIP!](/assets/img/preview_spaceship.png)

### What are we trying to do?

Imagine you start stacking a few Lego blocks and then an AI/robot starts stacking blocks alongside you. Ideally, the AI can intuitively pick up what you are trying to build. Or even better, the AI's blocks inspire you to take your build in a different direction you never imagined beforehand!

(This can happen in either the real-world with a robot arm stacking blocks OR a virtual/extended reality environment with 3D model blocks appearing wherever you/AI wants)

What would it take to get such a human-AI co-creation system to work?
 - How would we train the AI to learn how to build different shapes, step-by-step?
 - How would we train the AI to understand what shapes are being built, given only a few of them?

And on the other hand, how would it feel for human beings to interact with such an AI? 
 - Could we do everything without verbal communication? 
 - Would we really appreciate the AI's work or get annoyed?
 - Could we get inspired into new directions for making? Or will we quickly converge with the AI on a single solution?
 - (Or will we let it just take over since it seems so much more intelligent than us?)


### What is new about our approach?

Large language models, like ChatGPT, point to new ways of verbally communicating with AI. Generative image AI, like Midjourney, point to new ways for designers to get assistance from AI through verbal language.

But designs are not just defined by written words. And designers operate beyond the space of natural language.

Current state-of-the-art research on embodied AI focuses on related issues: how can AI develop a higher level reasoning and learn through multi-modal interactions with the world?

An embodied AI that can interact with designers through direct manipulation of the objects may present both benefits and challenges in user experience.


### If we succeed, what difference do we think it will make?

For now, this project serves as a "toy data experiment" for an embodied AI with human-in-the-loop.

But it can one day lay the foundation for various applications for designers of all sorts: architectural designers during concept massing, product designers developing novel form factors, industrial engineers developing packaging...even making your own spaceship!

![spaceship-guy](/assets/img/spaceship/lego_guy.gif)


### Excited?

This project is currently in progress on my [GitHub](https://github.com/holistudio/project-spaceship).

The dev log for this project can be found [here](https://github.com/holistudio/project-spaceship/blob/main/UPDATES.md).

Feel free to reach out and shoot me an email at daniel.bin.lu [at] gmail [dot] com.

